{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12847885,"sourceType":"datasetVersion","datasetId":8083039},{"sourceId":12851054,"sourceType":"datasetVersion","datasetId":8128075},{"sourceId":259171175,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Do this only in Colab notebooks! Otherwise use pip install unsloth\n!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo -q\n!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer -q\n!pip install --no-deps unsloth -q","metadata":{"_uuid":"b7e3038a-5414-472a-965d-747b18da57ef","_cell_guid":"363d34eb-2b89-47a9-baae-d8aedc823a83","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:53:25.331716Z","iopub.execute_input":"2025-08-31T14:53:25.331981Z","iopub.status.idle":"2025-08-31T14:53:40.544760Z","shell.execute_reply.started":"2025-08-31T14:53:25.331951Z","shell.execute_reply":"2025-08-31T14:53:40.544099Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nunsloth-zoo 2025.8.9 requires msgspec, which is not installed.\nunsloth-zoo 2025.8.9 requires tyro, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport gc\nimport json\nimport os\nfrom PIL import Image\nfrom unsloth import FastVisionModel\nfrom typing import Union, Dict, List, Optional\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport time","metadata":{"_uuid":"b933272b-e8c2-47d1-80f0-b976a7048339","_cell_guid":"8047e548-5db7-44c2-8b8e-bddc1392e815","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:53:40.545602Z","iopub.execute_input":"2025-08-31T14:53:40.545797Z","iopub.status.idle":"2025-08-31T14:54:33.018310Z","shell.execute_reply.started":"2025-08-31T14:53:40.545774Z","shell.execute_reply":"2025-08-31T14:54:33.017501Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-08-31 14:53:58.914509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756652039.244777      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756652039.339965      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===================================================================\n# Block 1: Data Loading and Utility Functions (MODIFIED FOR TRAIN SET)\n# ===================================================================\n\nimport json\nimport os\nimport re\nfrom PIL import Image\n\ndef load_train_data() -> tuple:\n    \"\"\"\n    Load all training data, law DB, and pre-extracted article details.\n    The 'answer' is already included in the training JSON.\n    \"\"\"\n    train_json_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/vlsp_2025_train.json\"\n    law_db_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/law_db/vlsp2025_law_new.json\"\n    extracted_data_path = \"/kaggle/input/vlsp-summarize-final/train_vision_rule_extraction_results.csv\"\n\n    print(f\"Loading training data from: {train_json_path}\")\n    print(f\"Loading law database from: {law_db_path}\")\n    print(f\"Loading extracted article data from: {extracted_data_path}\")\n\n    with open(train_json_path, 'r', encoding='utf-8') as f:\n        # Training data already contains the answer key for all items\n        train_questions = json.load(f)\n    with open(law_db_path, 'r', encoding='utf-8') as f:\n        law_database = json.load(f)\n\n    extracted_data_df = pd.read_csv(extracted_data_path)\n\n    print(f\"Loaded {len(train_questions)} total training questions.\")\n    print(f\"Loaded {len(law_database)} laws in database.\")\n    print(f\"Loaded {len(extracted_data_df)} rows from extracted data CSV.\")\n    \n    return train_questions, law_database, extracted_data_df\n\n\ndef get_relevant_articles(question_data: dict, law_database: list) -> list:\n    \"\"\"\n    Extract relevant articles for a given question from the raw law database.\n    \"\"\"\n    relevant_articles = []\n    for ref_article in question_data.get(\"relevant_articles\", []):\n        law_id, article_id = ref_article[\"law_id\"], ref_article[\"article_id\"]\n        for law in law_database:\n            if law[\"id\"] == law_id:\n                for article in law[\"articles\"]:\n                    if article[\"id\"] == article_id:\n                        relevant_articles.append({\n                            \"law_id\": law_id, \"law_title\": law[\"title\"], \"article_id\": article[\"id\"],\n                            \"article_title\": article[\"title\"], \"article_text\": article[\"text\"]\n                        })\n                        break\n                break\n    return relevant_articles\n\n\ndef clean_article_text(text: str) -> str:\n    \"\"\"\n    Clean article text by removing image and table tags.\n    \"\"\"\n    clean_text = re.sub(r'<<IMAGE: (.*?) /IMAGE>>', '', text)\n    return re.sub(r'<<TABLE: (.*?) /TABLE>>', '', clean_text, flags=re.DOTALL).strip()\n\n\ndef resize_image_if_needed(image_path: str, threshold: int = 768) -> Image.Image:\n    \"\"\"\n    Loads an image and resizes it proportionally if either dimension exceeds the threshold.\n    \"\"\"\n    img = Image.open(image_path).convert(\"RGB\")\n    return img","metadata":{"_uuid":"4869941d-df8a-4b7d-a1b9-55afe7b1d347","_cell_guid":"94552239-2867-479c-86c0-107501d1bc9b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.020061Z","iopub.execute_input":"2025-08-31T14:54:33.020325Z","iopub.status.idle":"2025-08-31T14:54:33.028932Z","shell.execute_reply.started":"2025-08-31T14:54:33.020306Z","shell.execute_reply":"2025-08-31T14:54:33.028206Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ===================================================================\n# Block 2: Prompt Generation and Processing (ADJUSTED FOR NEW EXTRACTION)\n# ===================================================================\n\ndef make_prompt(\n    question_id: str,\n    question: str,\n    choices: Optional[Dict[str, str]],\n    question_type: str,\n    relevant_articles: List[dict], # Used only for the fallback mechanism\n    extracted_data_df: pd.DataFrame\n) -> str:\n    \"\"\"\n    Creates a formatted CoT prompt using pre-extracted data (one entry per question)\n    with a fallback to the raw law DB.\n    \"\"\"\n    prompt_parts = [\"Báº¡n lÃ  má»™t chuyÃªn gia vá» luáº­t giao thÃ´ng Viá»‡t Nam. HÃ£y tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c cung cáº¥p.\\n\"]\n\n    if question_type == \"Multiple choice\":\n        extend_2 = \"PhÃ¢n tÃ­ch luáº­t, cÃ¢u há»i vÃ  láº§n lÆ°á»£t phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D. Giáº£i thÃ­ch táº¡i sao cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ  Ä‘Ãºng, vÃ  cÃ¡c cÃ¢u tráº£ lá»i cÃ²n láº¡i lÃ  sai\"\n        step_4 = \"Step 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\"\n    else: # Yes/No\n        extend_2 = \"PhÃ¢n tÃ­ch luáº­t vÃ  cÃ¢u há»i, phÃ¢n tÃ­ch cho cáº£ hai hÆ°á»›ng lÃ  cÃ¢u tráº£ lá»i sai vÃ  cÃ¢u tráº£ lá»i Ä‘Ãºng.\"\n        step_4 = \"Step 3: [ChÃº Ã½ xÃ¡c Ä‘á»‹nh Ä‘Ã¢y lÃ  má»‡nh Ä‘á» kháº³ng Ä‘á»‹nh hay phá»§ Ä‘á»‹nh.]\"\n        \n    prompt_parts.extend([\n        \"\\n# INSTRUCTION\",\n        \"HÃ£y suy nghÄ© tá»«ng bÆ°á»›c vÃ  tráº£ lá»i theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u:\",\n        extend_2,\n    ])\n    \n    question_extraction = extracted_data_df[extracted_data_df['question_id'] == question_id]\n\n    prompt_parts.append(\"\\n# BIá»‚N BÃO TRONG áº¢NH:\")\n    \n    use_fallback = True\n    if not question_extraction.empty:\n        row = question_extraction.iloc[0]\n        # The training extraction script uses 'raw' which contains all details\n        raw_extraction = row.get('raw')\n        if pd.notna(raw_extraction) and \"error\" not in str(raw_extraction).lower():\n            prompt_parts.append(raw_extraction)\n            use_fallback = False\n\n    # --- FALLBACK LOGIC ---\n    if use_fallback:\n        print(f\"  -> NOTE: Using fallback for question {question_id}. No valid extraction found.\")\n        article_count = 0\n        \n        for article in relevant_articles:\n            article_text = clean_article_text(article['article_text'])\n            text_snippet = \" \".join(article_text.split()[:100])\n            if len(article_text.split()) > 100:\n                text_snippet += \"...\"\n\n            prompt_parts.extend([\n                f\"## TÃªn: {article['article_title']}\",\n                f\"Ná»™i dung: {text_snippet}\",\n                \"\"\n            ])\n            article_count += 1\n        \n        if article_count == 0: \n            prompt_parts.append(\"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin luáº­t liÃªn quan.\")\n\n    general_knowledge = \"\"\"# EXCEPTION\nKhÃ´ng chá»‹u tÃ¡c Ä‘á»™ng cá»§a biá»ƒn bÃ¡o: xe cáº¥p cá»©u, xe cáº£nh sÃ¡t, xe Æ°u tiÃªn.\"\"\"\n    prompt_parts.append(general_knowledge)\n        \n    prompt_parts.extend([\n        \"\\n# Äá»ŠNH Dáº NG OUTPUT\",\n        \"Cung cáº¥p cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng theo Ä‘á»‹nh dáº¡ng sau, khÃ´ng thÃªm báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c:\",\n        \"<reasoning>\",\n        \"Step 1: [PhÃ¢n tÃ­ch cÃ¢u há»i]\",\n        \"Step 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\",\n        step_4,\n        \"</reasoning>\",\n    ])\n\n    if question_type == \"Multiple choice\":\n        prompt_parts.append(\"<answer>Chá»‰ má»™t chá»¯ cÃ¡i (A, B, C, hoáº·c D)</answer>\")\n    else: # Yes/No\n        prompt_parts.append(\"<answer>Chá»‰ 'True' hoáº·c 'False'</answer>\")\n\n    prompt_parts.extend([\"# CÃ‚U Há»I:\", f\"{question}\\n\"])\n\n    if question_type == \"Multiple choice\" and choices:\n        prompt_parts.append(\"# CÃC Lá»°A CHá»ŒN:\")\n        for key, value in choices.items():\n            prompt_parts.append(f\"<{key}>{value}</{key}>\")\n\n    prompt_parts.append(\"# OUTPUT\")\n    return \"\\n\".join(prompt_parts)\n\n\ndef get_train_image_path(image_id: str) -> str:\n    \"\"\"\n    Get the full path to a training image.\n    \"\"\"\n    base_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/train_images/train_images\"\n    image_filename = f\"{image_id}.jpg\"\n    \n    image_path = os.path.join(base_path, image_filename)\n    if not os.path.exists(image_path):\n        image_path = image_path.replace(\".jpg\", \".png\")\n    return image_path\n\n\ndef process_train_question(question_data: dict, law_database: list, extracted_data_df: pd.DataFrame) -> tuple:\n    \"\"\"\n    Process a single training question to get prompt, image path, and answer.\n    \"\"\"\n    prompt = make_prompt(\n        question_id=question_data[\"id\"],\n        question=question_data[\"question\"],\n        choices=question_data.get(\"choices\"),\n        question_type=question_data[\"question_type\"],\n        relevant_articles=get_relevant_articles(question_data, law_database),\n        extracted_data_df=extracted_data_df\n    )\n    image_path = get_train_image_path(question_data[\"image_id\"])\n    return prompt, image_path, question_data.get(\"answer\"), question_data[\"id\"]","metadata":{"_uuid":"db3e8eb8-b945-4a06-9851-bfe7a408c674","_cell_guid":"f97fe3b5-14b9-4da7-9906-4952cf37388e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.029751Z","iopub.execute_input":"2025-08-31T14:54:33.030005Z","iopub.status.idle":"2025-08-31T14:54:33.065580Z","shell.execute_reply.started":"2025-08-31T14:54:33.029983Z","shell.execute_reply":"2025-08-31T14:54:33.065001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ===================================================================\n# Block 3: Inference Class (UNCHANGED)\n# ===================================================================\n\nclass SimpleVisionInference:\n    \"\"\"Simple 2-GPU vision model inference using Unsloth.\"\"\"\n    def __init__(self, model_name: str = \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\"):\n        self.model, self.processor = None, None\n        self.model_name = model_name\n        print(f\"Available GPUs: {torch.cuda.device_count()}\")\n        device_map = \"balanced\" if torch.cuda.device_count() >= 2 else \"auto\"\n        print(f\"Loading model from: {model_name} with device_map: {device_map}\")\n        self._load_model(device_map)\n        print(\"Model loaded successfully!\")\n\n    def _load_model(self, device_map: str):\n        try:\n            self.model, self.processor = FastVisionModel.from_pretrained(\n                self.model_name, load_in_4bit=True, device_map=device_map\n            )\n            FastVisionModel.for_inference(self.model)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model {self.model_name}: {str(e)}\")\n\n    def inference(self, prompt: str, image_path: str, max_new_tokens: int = 8, **kwargs) -> str:\n        \"\"\"\n        Perform inference, now with integrated resizing and logging.\n        \"\"\"\n        try:\n            pil_image = resize_image_if_needed(image_path, threshold=768)\n            print(f\"\\nLOG: Processing Image '{os.path.basename(image_path)}'\")\n            print(f\"  Image Size (for Inference): {pil_image.size} | Prompt Chars: {len(prompt)}\")\n            device = next(self.model.parameters()).device\n            messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": prompt}]}]\n            text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            inputs = self.processor(text=[text], images=[pil_image], return_tensors=\"pt\").to(device)\n            with torch.no_grad():\n                outputs = self.model.generate(\n                    **inputs,\n                    max_new_tokens=max_new_tokens,\n                    use_cache=True,\n                    temperature=0.1\n                )\n            return self.processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0].strip()\n        except Exception as e:\n            raise RuntimeError(f\"Inference failed: {str(e)}\")\n\n    def cleanup(self):\n        \"\"\"Clean up VRAM.\"\"\"\n        print(\"ğŸ§¹ Cleaning up VRAM...\")\n        del self.model\n        del self.processor\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        print(\"VRAM cleaned up\")\n\n    def __del__(self):\n        self.cleanup()","metadata":{"_uuid":"a75a815f-870d-4a4b-8e4f-20928f7e964e","_cell_guid":"6d1e9973-99e2-4582-8e9f-c7f7896110d9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.066511Z","iopub.execute_input":"2025-08-31T14:54:33.066681Z","iopub.status.idle":"2025-08-31T14:54:33.085274Z","shell.execute_reply.started":"2025-08-31T14:54:33.066668Z","shell.execute_reply":"2025-08-31T14:54:33.084707Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ===================================================================\n# Block 4: Full Dataset Inference Workflow (MODIFIED FOR TRAIN SET)\n# ===================================================================\n\ndef parse_cot_output(raw_output: str) -> (str, str):\n    \"\"\"\n    Parses the CoT output to extract reasoning and the final answer.\n    \"\"\"\n    reasoning_match = re.search(r\"<reasoning>(.*?)</reasoning>\", raw_output, re.DOTALL)\n    answer_match = re.search(r\"<answer>(.*?)</answer>\", raw_output, re.DOTALL)\n    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"No reasoning found.\"\n    answer = answer_match.group(1).strip() if answer_match else \"No answer found.\"\n    if(reasoning == \"No reasoning found.\"):\n        print(raw_output)\n    return reasoning, answer\n\ndef inference_all_questions(model_instance: SimpleVisionInference, questions: list, law_database: list, extracted_data_df: pd.DataFrame, output_csv: str):\n    \"\"\"\n    Run CoT inference on all training questions, evaluate, log periodically, and save results.\n    \"\"\"\n    results = []\n    correct_count, total_processed = 0, 0\n    start_time = time.time()\n    answer_map = {\"Yes\": \"True\", \"No\": \"False\"}\n\n    PROMPT_SANITY_CHECK_COUNT = 3\n\n    if not questions:\n        print(\"No questions to process.\")\n        return\n    print(f\"\\nğŸ”„ Running inference on a batch of {len(questions)} questions (from ID '{questions[0]['id']}' to '{questions[-1]['id']}')...\")\n    \n    for index, question_data in enumerate(tqdm(questions, desc=\"Processing Questions\")):\n        result_record = {\n            'question_id': question_data['id'],\n            'correct_answer': question_data.get('answer'),\n            'reasoning': '',\n            'model_answer': '',\n            'is_correct': False\n        }\n        \n        try:\n            prompt, image_path, correct_answer, _ = process_train_question(\n                question_data, law_database, extracted_data_df\n            )\n            \n            if index < PROMPT_SANITY_CHECK_COUNT:\n                print(f\"\\n--- PROMPT SANITY CHECK (Question: {question_data['id']}) ---\")\n                print(prompt)\n                print(\"--------------------------------------------------\")\n\n            if os.path.exists(image_path):\n                raw_model_output = model_instance.inference(prompt, image_path, max_new_tokens=1024)\n                reasoning, final_answer = parse_cot_output(raw_model_output)\n                \n                if index < PROMPT_SANITY_CHECK_COUNT:\n                    print(f\"\\n--- Sanity Check (Question: {question_data['id']}) ---\")\n                    print(f\"  Reasoning: {reasoning}\")\n                    print(f\"  Model Answer: {final_answer} | Correct Answer: {correct_answer}\")\n                    print(\"-------------------------------------------------\")\n\n                is_correct = False\n                if question_data['question_type'] == \"Yes/No\":\n                    if final_answer == answer_map.get(correct_answer):\n                        is_correct = True\n                else: # Handles \"Multiple choice\"\n                    if final_answer == correct_answer:\n                        is_correct = True\n                \n                if is_correct:\n                    correct_count += 1\n\n                result_record.update({\n                    'reasoning': reasoning,\n                    'model_answer': final_answer,\n                    'is_correct': is_correct\n                })\n                total_processed += 1\n            else:\n                result_record['model_answer'] = \"ERROR: Image not found\"\n                print(f\"  Skipping {question_data['id']}: Image not found at {image_path}\")\n                \n        except Exception as e:\n            result_record['model_answer'] = f\"ERROR: {e}\"\n            print(f\"\\n  âŒ Error processing question {question_data['id']}: {e}\")\n        \n        results.append(result_record)\n\n    df = pd.DataFrame(results)\n    df.to_csv(output_csv, index=False, encoding='utf-8')\n    total_time = time.time() - start_time\n    accuracy = (correct_count / total_processed * 100) if total_processed > 0 else 0\n    \n    print(\"\\n\" + \"=\"*50 + \"\\nğŸ“Š INFERENCE SUMMARY\")\n    print(f\"Total Questions Processed: {total_processed}, Correct Guesses: {correct_count}\")\n    print(f\"Accuracy: {accuracy:.2f}%\")\n    if total_time > 0:\n        print(f\"Images per Second: {total_processed / total_time:.2f} img/s\")\n    print(f\"Results for this batch saved to: {output_csv}\")","metadata":{"_uuid":"a5e3ed92-1177-403a-a306-2975d8b16bb6","_cell_guid":"f1092391-2da3-43f3-9d6b-445a363375a2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.086039Z","iopub.execute_input":"2025-08-31T14:54:33.086302Z","iopub.status.idle":"2025-08-31T14:54:33.107720Z","shell.execute_reply.started":"2025-08-31T14:54:33.086279Z","shell.execute_reply":"2025-08-31T14:54:33.107209Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- MODIFIED: Main function now handles the training data ---\ndef main():\n    \"\"\"\n    Main function for running inference on the training set.\n    \"\"\"\n    print(\"ğŸš€ Vietnamese Law QA System - Training Set Inference\")\n    print(\"=\" * 70)\n\n    output_csv = \"train_inference_results.csv\"\n    model_instance = None\n    try:\n        print(\"ğŸ“š Loading Vietnamese Law Training Dataset and Extracted Data...\")\n        train_questions, law_database, extracted_data_df = load_train_data()\n\n        print(\"\\nğŸ¤– Initializing Qwen2.5-VL Model...\")\n        model_instance = SimpleVisionInference()\n\n        inference_all_questions(\n            model_instance=model_instance,\n            questions=train_questions[:25], # Using a slice for initial testing\n            law_database=law_database,\n            extracted_data_df=extracted_data_df,\n            output_csv=output_csv\n        )\n\n        print(f\"\\nğŸ‰ Inference completed! Check {output_csv} for detailed results.\")\n\n    except Exception as e:\n        print(f\"âŒ A critical error occurred: {e}\")\n        import traceback\n        traceback.print_exc()\n\n    finally:\n        if model_instance:\n            del model_instance\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"95b27ce7-5c24-4d24-bf8b-75d0fa97a768","_cell_guid":"3b13d338-2474-4885-8bf6-d2d34ef1d4c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-31T14:54:33.108554Z","iopub.execute_input":"2025-08-31T14:54:33.108782Z","iopub.status.idle":"2025-08-31T15:11:39.910494Z","shell.execute_reply.started":"2025-08-31T14:54:33.108756Z","shell.execute_reply":"2025-08-31T15:11:39.909829Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"ğŸš€ Vietnamese Law QA System - Training Set Inference\n======================================================================\nğŸ“š Loading Vietnamese Law Training Dataset and Extracted Data...\nLoading training data from: /kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/vlsp_2025_train.json\nLoading law database from: /kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/law_db/vlsp2025_law_new.json\nLoading extracted article data from: /kaggle/input/vlsp-summarize-final/train_vision_rule_extraction_results.csv\nLoaded 530 total training questions.\nLoaded 2 laws in database.\nLoaded 441 rows from extracted data CSV.\n\nğŸ¤– Initializing Qwen2.5-VL Model...\nAvailable GPUs: 2\nLoading model from: unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit with device_map: balanced\n==((====))==  Unsloth 2025.8.10: Fast Qwen2_5_Vl patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8538bb9f0b194a3eb1046a1ded46eb51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be8ec4f9818049a1b5363f69a6827047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b506770644c946e3ad9438b7f094f545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b9f1f135a77435baebdba9506ce0a1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3278350719a54d08b815f56046439447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef88ac043c9470cb870baa6e52f370d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e08998e8d54dbdae06bd1f39562cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38883b79c35f4efb86159645d9f3d62e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e4ea30e59e340aa9c029e5edb60cfa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211ac934326045baa7eeda2e1580be12"}},"metadata":{}},{"name":"stderr","text":"You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a08ee15545e4c0c8ec6a2760e75f596"}},"metadata":{}},{"name":"stdout","text":"Model loaded successfully!\n\nğŸ”„ Running inference on a batch of 25 questions (from ID 'train_1' to 'train_25')...\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   0%|          | 0/25 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_1. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_1) ---\nBáº¡n lÃ  má»™t chuyÃªn gia vá» luáº­t giao thÃ´ng Viá»‡t Nam. HÃ£y tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c cung cáº¥p.\n\n\n# INSTRUCTION\nHÃ£y suy nghÄ© tá»«ng bÆ°á»›c vÃ  tráº£ lá»i theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u:\nPhÃ¢n tÃ­ch luáº­t, cÃ¢u há»i vÃ  láº§n lÆ°á»£t phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D. Giáº£i thÃ­ch táº¡i sao cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ  Ä‘Ãºng, vÃ  cÃ¡c cÃ¢u tráº£ lá»i cÃ²n láº¡i lÃ  sai\n\n# BIá»‚N BÃO TRONG áº¢NH:\n## TÃªn: Ã nghÄ©a sá»­ dá»¥ng cÃ¡c biá»ƒn bÃ¡o cáº¥m\nNá»™i dung: 22.1. Biá»ƒn bÃ¡o cáº¥m cÃ³ mÃ£ P (cáº¥m) vÃ  DP (háº¿t cáº¥m) vá»›i tÃªn cÃ¡c biá»ƒn nhÆ° sau: - Biá»ƒn sá»‘ P.101: ÄÆ°á»ng cáº¥m; - Biá»ƒn sá»‘ P.102: Cáº¥m Ä‘i ngÆ°á»£c chiá»u; - Biá»ƒn sá»‘ P.103a: Cáº¥m xe Ã´ tÃ´; - Biá»ƒn sá»‘ P.103(b,c): Cáº¥m xe Ã´ tÃ´ ráº½ trÃ¡i; Cáº¥m xe Ã´tÃ´ ráº½ pháº£i; - Biá»ƒn sá»‘ P.104: Cáº¥m xe mÃ¡y; - Biá»ƒn sá»‘ P.105: Cáº¥m xe Ã´ tÃ´ vÃ  xe mÃ¡y; - Biá»ƒn sá»‘ P.106(a,b): Cáº¥m xe Ã´ tÃ´ táº£i; - Biá»ƒn sá»‘ P.106c: Cáº¥m cÃ¡c xe chá»Ÿ hÃ ng nguy hiá»ƒm; - Biá»ƒn sá»‘ P.107: Cáº¥m xe Ã´...\n\n# EXCEPTION\nKhÃ´ng chá»‹u tÃ¡c Ä‘á»™ng cá»§a biá»ƒn bÃ¡o: xe cáº¥p cá»©u, xe cáº£nh sÃ¡t, xe Æ°u tiÃªn.\n\n# Äá»ŠNH Dáº NG OUTPUT\nCung cáº¥p cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng theo Ä‘á»‹nh dáº¡ng sau, khÃ´ng thÃªm báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c:\n<reasoning>\nStep 1: [PhÃ¢n tÃ­ch cÃ¢u há»i]\nStep 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\nStep 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\n</reasoning>\n<answer>Chá»‰ má»™t chá»¯ cÃ¡i (A, B, C, hoáº·c D)</answer>\n# CÃ‚U Há»I:\nBiá»ƒn bÃ¡o cáº¥m xe khÃ¡ch trÃªn 29 chá»— Ä‘Æ°á»£c Ã¡p dá»¥ng trong cÃ¡c khoáº£ng thá»i gian nÃ o? \n\n# CÃC Lá»°A CHá»ŒN:\n<A>Tá»« 6:30 Ä‘áº¿n 8:00 vÃ  tá»« 16:30 Ä‘áº¿n 18:30; ngoÃ i cÃ¡c khoáº£ng thá»i gian nÃ y khÃ´ng Ä‘Æ°á»£c phÃ©p lÆ°u thÃ´ng.</A>\n<B>Tá»« 6:30 Ä‘áº¿n 8:00 vÃ  tá»« 16:30 Ä‘áº¿n 18:30; ngoÃ i cÃ¡c khoáº£ng thá»i gian nÃ y Ä‘Æ°á»£c phÃ©p lÆ°u thÃ´ng.</B>\n<C>Cáº¥m lÆ°u thÃ´ng cáº£ ngÃ y.</C>\n<D>D. KhÃ´ng cáº¥m xe khÃ¡ch trÃªn 29 chá»— lÆ°u thÃ´ng.</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1616\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   4%|â–         | 1/25 [01:26<34:32, 86.34s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_1) ---\n  Reasoning: Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i\n- CÃ¢u há»i yÃªu cáº§u tÃ¬m hiá»ƒu thá»i gian Ã¡p dá»¥ng cá»§a biá»ƒn bÃ¡o cáº¥m xe khÃ¡ch trÃªn 29 chá»—.\n\nStep 2: PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH\n- Biá»ƒn bÃ¡o cáº¥m xe khÃ¡ch trÃªn 29 chá»— cÃ³ hÃ¬nh dáº¡ng lÃ  má»™t hÃ¬nh trÃ²n Ä‘á» vá»›i biá»ƒu tÆ°á»£ng xe khÃ¡ch bá»‹ cháº¥m xanh, kÃ¨m theo Ä‘Ã³ lÃ  má»™t biá»ƒn phá»¥ thÃ´ng bÃ¡o thá»i gian Ã¡p dá»¥ng.\n- Thá»i gian cá»¥ thá»ƒ Ä‘Æ°á»£c ghi rÃµ trÃªn biá»ƒn phá»¥ lÃ  tá»« 06:30 Ä‘áº¿n 08:00 vÃ  tá»« 16:30 Ä‘áº¿n 18:30.\n\nStep 3: Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.\n- A: \"Tá»« 6:30 Ä‘áº¿n 8:00 vÃ  tá»« 16:30 Ä‘áº¿n 18:30; ngoÃ i cÃ¡c khoáº£ng thá»i gian nÃ y khÃ´ng Ä‘Æ°á»£c phÃ©p lÆ°u thÃ´ng.\" - ÄÃ¢y lÃ  Ä‘Ã¡p Ã¡n chÃ­nh xÃ¡c vÃ¬ nÃ³ trÃ¹ng khá»›p hoÃ n toÃ n vá»›i thÃ´ng tin trÃªn biá»ƒn phá»¥.\n- B: \"Tá»« 6:30 Ä‘áº¿n 8:00 vÃ  tá»« 16:30 Ä‘áº¿n 18:30; ngoÃ i cÃ¡c khoáº£ng thá»i gian nÃ y Ä‘Æ°á»£c phÃ©p lÆ°u thÃ´ng.\" - ÄÃ¢y lÃ  Ä‘Ã¡p Ã¡n sai vÃ¬ nÃ³ trÃ¡i ngÆ°á»£c vá»›i thÃ´ng tin trÃªn biá»ƒn phá»¥.\n- C: \"Cáº¥m lÆ°u thÃ´ng cáº£ ngÃ y.\" - ÄÃ¢y lÃ  Ä‘Ã¡p Ã¡n sai vÃ¬ chá»‰ cÃ³ hai khoáº£ng thá»i gian cá»¥ thá»ƒ Ä‘Æ°á»£c cáº¥m, khÃ´ng pháº£i cáº£ ngÃ y.\n- D: \"D. KhÃ´ng cáº¥m xe khÃ¡ch trÃªn 29 chá»— lÆ°u thÃ´ng.\" - ÄÃ¢y lÃ  Ä‘Ã¡p Ã¡n sai vÃ¬ biá»ƒn bÃ¡o Ä‘Ã£æ˜ç¡®è§„å®šç¦æ­¢ç‰¹å®šè½¦è¾†åœ¨ç‰¹å®šæ—¶é—´æ®µå†…é€šè¡Œã€‚\n  Model Answer: A | Correct Answer: B\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_2. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_2) ---\nBáº¡n lÃ  má»™t chuyÃªn gia vá» luáº­t giao thÃ´ng Viá»‡t Nam. HÃ£y tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c cung cáº¥p.\n\n\n# INSTRUCTION\nHÃ£y suy nghÄ© tá»«ng bÆ°á»›c vÃ  tráº£ lá»i theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u:\nPhÃ¢n tÃ­ch luáº­t, cÃ¢u há»i vÃ  láº§n lÆ°á»£t phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D. Giáº£i thÃ­ch táº¡i sao cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ  Ä‘Ãºng, vÃ  cÃ¡c cÃ¢u tráº£ lá»i cÃ²n láº¡i lÃ  sai\n\n# BIá»‚N BÃO TRONG áº¢NH:\n## TÃªn: Vá»‹ trÃ­ Ä‘áº·t biá»ƒn bÃ¡o cáº¥m theo chiá»u Ä‘i vÃ  hÆ°á»›ng hiá»‡u lá»±c cá»§a biá»ƒn\nNá»™i dung: 26.1. Biá»ƒn bÃ¡o cáº¥m Ä‘Æ°á»£c Ä‘áº·t á»Ÿ nÆ¡i Ä‘Æ°á»ng giao nhau hoáº·c trÆ°á»›c má»™t vá»‹ trÃ­ trÃªn Ä‘Æ°á»ng cáº§n cáº¥m. Biá»ƒn cÃ³ hiá»‡u lá»±c báº¯t Ä‘áº§u tá»« vá»‹ trÃ­ Ä‘áº·t biá»ƒn trá»Ÿ Ä‘i. Náº¿u vÃ¬ lÃ½ do nÃ o Ä‘Ã³, biá»ƒn Ä‘áº·t cÃ¡ch xa vá»‹ trÃ­ Ä‘á»‹nh cáº¥m thÃ¬ pháº£i Ä‘áº·t biá»ƒn phá»¥ sá»‘ S.502 Ä‘á»ƒ chá»‰ rÃµ khoáº£ng cÃ¡ch tá»« sau biá»ƒn cáº¥m Ä‘áº¿n vá»‹ trÃ­ biá»ƒn báº¯t Ä‘áº§u cÃ³ hiá»‡u lá»±c. 26.2. Khi cáº§n thiáº¿t Ä‘á»ƒ chá»‰ rÃµ hÆ°á»›ng tÃ¡c dá»¥ng cá»§a biá»ƒn vÃ  chá»‰ vá»‹ trÃ­ báº¯t Ä‘áº§u hay vá»‹ trÃ­ káº¿t thÃºc hiá»‡u lá»±c cá»§a biá»ƒn pháº£i...\n\n## TÃªn: Biá»ƒn bÃ¡o giao thÃ´ng cÃ³ thÃ´ng tin thay Ä‘á»•i, biá»ƒn bÃ¡o táº¡m thá»i\nNá»™i dung: 14.1. Biá»ƒn bÃ¡o giao thÃ´ng cÃ³ thÃ´ng tin thay Ä‘á»•i (biá»ƒn bÃ¡o VMS): lÃ  biá»ƒn bÃ¡o Ä‘iá»‡n tá»­ cÃ³ thá»ƒ thay Ä‘á»•i thÃ´ng tin trÃªn cÃ¹ng má»™t máº·t biá»ƒn. Biá»ƒn Ä‘Æ°á»£c sá»­ dá»¥ng khi thÃ´ng tin hiá»ƒn thá»‹ trÃªn biá»ƒn bÃ¡o cáº§n pháº£i thay Ä‘á»•i tÃ¹y theo tÃ¬nh huá»‘ng giao thÃ´ng. TÃ¹y theo má»¥c Ä‘Ã­ch, thÃ´ng tin trÃªn biá»ƒn cÃ³ thá»ƒ lÃ  chá»‰ dáº«n, cáº¥m, hiá»‡u lá»‡nh hoáº·c bÃ¡o nguy hiá»ƒm vÃ  cáº£nh bÃ¡o. Biá»ƒn khÃ´ng Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ quáº£ng cÃ¡o, sá»­ dá»¥ng hÃ¬nh hoáº¡t há»a, nháº¥p nhÃ¡y, cÃ¡c hÃ¬nh cÃ³ tÃ­nh cháº¥t di chuyá»ƒn. Khi á»Ÿ má»™t vá»‹ trÃ­...\n\n# EXCEPTION\nKhÃ´ng chá»‹u tÃ¡c Ä‘á»™ng cá»§a biá»ƒn bÃ¡o: xe cáº¥p cá»©u, xe cáº£nh sÃ¡t, xe Æ°u tiÃªn.\n\n# Äá»ŠNH Dáº NG OUTPUT\nCung cáº¥p cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng theo Ä‘á»‹nh dáº¡ng sau, khÃ´ng thÃªm báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c:\n<reasoning>\nStep 1: [PhÃ¢n tÃ­ch cÃ¢u há»i]\nStep 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\nStep 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\n</reasoning>\n<answer>Chá»‰ má»™t chá»¯ cÃ¡i (A, B, C, hoáº·c D)</answer>\n# CÃ‚U Há»I:\nNhÆ°Ìƒng loaÌ£i phÆ°Æ¡ng tiÃªÌ£n naÌ€o biÌ£ cÃ¢Ìm trÃªn Ä‘oaÌ£n Ä‘Æ°Æ¡Ì€ng naÌ€y\n\n# CÃC Lá»°A CHá»ŒN:\n<A>Xe khaÌch trÃªn 29 chÃ´Ìƒ</A>\n<B>Ã´ tÃ´ con</B>\n<C>Xe maÌy</C>\n<D>Xe Ä‘aÌ£p</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1973\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   8%|â–Š         | 2/25 [02:00<21:22, 55.75s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_2) ---\n  Reasoning: Step 1: [PhÃ¢n tÃ­ch cÃ¢u há»i]\nCÃ¢u há»i yÃªu cáº§u xÃ¡c Ä‘á»‹nh nhá»¯ng loáº¡i phÆ°Æ¡ng tiá»‡n nÃ o bá»‹ cáº¥m trÃªn Ä‘oáº¡n Ä‘Æ°á»ng nÃ y. \n\nStep 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\nBiá»ƒn bÃ¡o cáº¥m xe khÃ¡ch trÃªn 29 chá»— Ä‘Æ°á»£c Ä‘áº·t á»Ÿ vá»‹ trÃ­ Ä‘Æ°á»ng giao nhau hoáº·c trÆ°á»›c vá»‹ trÃ­ cáº§n cáº¥m. Biá»ƒn cÃ³ hiá»‡u lá»±c báº¯t Ä‘áº§u tá»« vá»‹ trÃ­ Ä‘áº·t biá»ƒn trá»Ÿ Ä‘i. ThÃ´ng tin trÃªn biá»ƒn cho biáº¿t thá»i gian cáº¥m tá»« 06:30-08:00 vÃ  16:30-18:30.\n\nStep 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\n- A: Xe khÃ¡ch trÃªn 29 chá»— - ÄÃ¢y chÃ­nh lÃ  thÃ´ng tin Ä‘Æ°á»£c hiá»ƒn thá»‹ trÃªn biá»ƒn bÃ¡o cáº¥m.\n- B: Ã´ tÃ´ con - KhÃ´ng cÃ³ thÃ´ng tin nÃ o trÃªn biá»ƒn bÃ¡o cáº¥m vá» viá»‡c cáº¥m Ã´ tÃ´ con.\n- C: Xe mÃ¡y - KhÃ´ng cÃ³ thÃ´ng tin nÃ o trÃªn biá»ƒn bÃ¡o cáº¥m vá» viá»‡c cáº¥m xe mÃ¡y.\n- D: Xe Ä‘áº¡p - KhÃ´ng cÃ³ thÃ´ng tin nÃ o trÃªn biá»ƒn bÃ¡o cáº¥m vá» viá»‡c cáº¥m xe Ä‘áº¡p.\n  Model Answer: A | Correct Answer: A\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_3. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_3) ---\nBáº¡n lÃ  má»™t chuyÃªn gia vá» luáº­t giao thÃ´ng Viá»‡t Nam. HÃ£y tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c cung cáº¥p.\n\n\n# INSTRUCTION\nHÃ£y suy nghÄ© tá»«ng bÆ°á»›c vÃ  tráº£ lá»i theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u:\nPhÃ¢n tÃ­ch luáº­t, cÃ¢u há»i vÃ  láº§n lÆ°á»£t phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D. Giáº£i thÃ­ch táº¡i sao cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ  Ä‘Ãºng, vÃ  cÃ¡c cÃ¢u tráº£ lá»i cÃ²n láº¡i lÃ  sai\n\n# BIá»‚N BÃO TRONG áº¢NH:\n## TÃªn: Vá»‹ trÃ­ Ä‘áº·t biá»ƒn bÃ¡o cáº¥m theo chiá»u Ä‘i vÃ  hÆ°á»›ng hiá»‡u lá»±c cá»§a biá»ƒn\nNá»™i dung: 26.1. Biá»ƒn bÃ¡o cáº¥m Ä‘Æ°á»£c Ä‘áº·t á»Ÿ nÆ¡i Ä‘Æ°á»ng giao nhau hoáº·c trÆ°á»›c má»™t vá»‹ trÃ­ trÃªn Ä‘Æ°á»ng cáº§n cáº¥m. Biá»ƒn cÃ³ hiá»‡u lá»±c báº¯t Ä‘áº§u tá»« vá»‹ trÃ­ Ä‘áº·t biá»ƒn trá»Ÿ Ä‘i. Náº¿u vÃ¬ lÃ½ do nÃ o Ä‘Ã³, biá»ƒn Ä‘áº·t cÃ¡ch xa vá»‹ trÃ­ Ä‘á»‹nh cáº¥m thÃ¬ pháº£i Ä‘áº·t biá»ƒn phá»¥ sá»‘ S.502 Ä‘á»ƒ chá»‰ rÃµ khoáº£ng cÃ¡ch tá»« sau biá»ƒn cáº¥m Ä‘áº¿n vá»‹ trÃ­ biá»ƒn báº¯t Ä‘áº§u cÃ³ hiá»‡u lá»±c. 26.2. Khi cáº§n thiáº¿t Ä‘á»ƒ chá»‰ rÃµ hÆ°á»›ng tÃ¡c dá»¥ng cá»§a biá»ƒn vÃ  chá»‰ vá»‹ trÃ­ báº¯t Ä‘áº§u hay vá»‹ trÃ­ káº¿t thÃºc hiá»‡u lá»±c cá»§a biá»ƒn pháº£i...\n\n# EXCEPTION\nKhÃ´ng chá»‹u tÃ¡c Ä‘á»™ng cá»§a biá»ƒn bÃ¡o: xe cáº¥p cá»©u, xe cáº£nh sÃ¡t, xe Æ°u tiÃªn.\n\n# Äá»ŠNH Dáº NG OUTPUT\nCung cáº¥p cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng theo Ä‘á»‹nh dáº¡ng sau, khÃ´ng thÃªm báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c:\n<reasoning>\nStep 1: [PhÃ¢n tÃ­ch cÃ¢u há»i]\nStep 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\nStep 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\n</reasoning>\n<answer>Chá»‰ má»™t chá»¯ cÃ¡i (A, B, C, hoáº·c D)</answer>\n# CÃ‚U Há»I:\nThá»i gian cáº¥m xe khÃ¡ch trÃªn 29 chá»— cÃ³ bá»‹ thay Ä‘á»•i theo mÃ¹a khÃ´ng?\n\n# CÃC Lá»°A CHá»ŒN:\n<A>Thá»i gian cáº¥m xe khÃ¡ch thay Ä‘á»•i vÃ o mÃ¹a hÃ¨ vÃ  mÃ¹a Ä‘Ã´ng</A>\n<B>Thá»i gian cáº¥m xe khÃ¡ch thay Ä‘á»•i vÃ o cÃ¡c ngÃ y lá»…, Táº¿t</B>\n<C>Thá»i gian cáº¥m xe khÃ¡ch cá»‘ Ä‘á»‹nh, khÃ´ng thay Ä‘á»•i theo mÃ¹a</C>\n<D>Thá»i gian cáº¥m xe khÃ¡ch chá»‰ Ã¡p dá»¥ng vÃ o giá» cao Ä‘iá»ƒm buá»•i sÃ¡ng</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1608\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  12%|â–ˆâ–        | 3/25 [02:41<17:56, 48.95s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_3) ---\n  Reasoning: Step 1: [PhÃ¢n tÃ­ch cÃ¢u há»i] \nCÃ¢u há»i há»i vá» viá»‡c thá»i gian cáº¥m xe khÃ¡ch trÃªn 29 chá»— cÃ³ thay Ä‘á»•i theo mÃ¹a hay khÃ´ng. \n\nStep 2: [PhÃ¢n tÃ­ch # BIá»‚N BÃO TRONG áº¢NH]\nBiá»ƒn bÃ¡o trong áº£nh chá»‰ ra thá»i gian cá»¥ thá»ƒ tá»« 06:30-08:00 vÃ  16:30-18:30 hÃ ng ngÃ y. KhÃ´ng cÃ³ thÃ´ng tin gÃ¬ vá» viá»‡c thá»i gian nÃ y thay Ä‘á»•i theo mÃ¹a.\n\nStep 3: [Duyá»‡t qua vÃ  phÃ¢n tÃ­ch cáº£ A, B, C vÃ  D.]\n- A: Thá»i gian cáº¥m xe khÃ¡ch thay Ä‘á»•i vÃ o mÃ¹a hÃ¨ vÃ  mÃ¹a Ä‘Ã´ng - KhÃ´ng cÃ³ thÃ´ng tin nÃ o cho tháº¥y thá»i gian nÃ y thay Ä‘á»•i theo mÃ¹a.\n- B: Thá»i gian cáº¥m xe khÃ¡ch thay Ä‘á»•i vÃ o cÃ¡c ngÃ y lá»…, Táº¿t - KhÃ´ng cÃ³ thÃ´ng tin nÃ o cho tháº¥y thá»i gian nÃ y thay Ä‘á»•i theo cÃ¡c ngÃ y lá»…, Táº¿t.\n- C: Thá»i gian cáº¥m xe khÃ¡ch cá»‘ Ä‘á»‹nh, khÃ´ng thay Ä‘á»•i theo mÃ¹a - ÄÃ¢y lÃ  lá»±a chá»n phÃ¹ há»£p vá»›i thÃ´ng tin trÃªn biá»ƒn bÃ¡o.\n- D: Thá»i gian cáº¥m xe khÃ¡ch chá»‰ Ã¡p dá»¥ng vÃ o giá» cao Ä‘iá»ƒm buá»•i sÃ¡ng - Thá»i gian trÃªn biá»ƒn bÃ¡o khÃ´ng chá»‰ Ã¡p dá»¥ng vÃ o giá» cao Ä‘iá»ƒm buá»•i sÃ¡ng mÃ  cÃ²n bao gá»“m cáº£ buá»•i chiá»u.\n\nVÃ¬ váº­y, cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng lÃ  Ä‘Ãºng lÃ  C.\n  Model Answer: C | Correct Answer: C\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_4. No valid extraction found.\n\nLOG: Processing Image 'train_1_20.jpg'\n  Image Size (for Inference): (500, 334) | Prompt Chars: 1828\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  16%|â–ˆâ–Œ        | 4/25 [03:32<17:22, 49.65s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_5. No valid extraction found.\n\nLOG: Processing Image 'train_1_10.jpg'\n  Image Size (for Inference): (1200, 1200) | Prompt Chars: 2245\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  20%|â–ˆâ–ˆ        | 5/25 [04:19<16:16, 48.81s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_6. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 1833\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  24%|â–ˆâ–ˆâ–       | 6/25 [05:03<14:58, 47.31s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_7. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 2446\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  28%|â–ˆâ–ˆâ–Š       | 7/25 [05:52<14:16, 47.60s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_8. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 2045\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [06:16<11:24, 40.29s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_9. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1377\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [06:47<09:57, 37.36s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_10. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1391\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [07:16<08:42, 34.84s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_11. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1781\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [08:02<08:55, 38.25s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_12. No valid extraction found.\n\nLOG: Processing Image 'train_1_6.jpg'\n  Image Size (for Inference): (600, 600) | Prompt Chars: 1415\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [08:43<08:26, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_13. No valid extraction found.\n\nLOG: Processing Image 'train_1_6.jpg'\n  Image Size (for Inference): (600, 600) | Prompt Chars: 1746\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [09:25<07:56, 39.75s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_14. No valid extraction found.\n\nLOG: Processing Image 'train_1_17.jpg'\n  Image Size (for Inference): (731, 487) | Prompt Chars: 1476\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [10:11<07:40, 41.84s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_15. No valid extraction found.\n\nLOG: Processing Image 'train_1_17.jpg'\n  Image Size (for Inference): (731, 487) | Prompt Chars: 1398\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [10:56<07:06, 42.70s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_16. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1613\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [11:38<06:21, 42.39s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_17. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1307\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [12:00<04:49, 36.24s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_18. No valid extraction found.\n\nLOG: Processing Image 'train_1_2.jpg'\n  Image Size (for Inference): (800, 522) | Prompt Chars: 1342\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [12:24<03:48, 32.66s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_19. No valid extraction found.\n\nLOG: Processing Image 'train_1_9.jpg'\n  Image Size (for Inference): (495, 341) | Prompt Chars: 1329\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [12:47<02:58, 29.74s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_20. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1493\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [13:17<02:29, 29.94s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_21. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1740\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [14:03<02:19, 34.85s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_22. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1817\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [14:43<01:48, 36.22s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_23. No valid extraction found.\n\nLOG: Processing Image 'train_1_2.jpg'\n  Image Size (for Inference): (800, 522) | Prompt Chars: 1773\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [15:12<01:08, 34.12s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_24. No valid extraction found.\n\nLOG: Processing Image 'train_1_9.jpg'\n  Image Size (for Inference): (495, 341) | Prompt Chars: 1692\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [15:50<00:35, 35.22s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_25. No valid extraction found.\n\nLOG: Processing Image 'train_1_20.jpg'\n  Image Size (for Inference): (500, 334) | Prompt Chars: 1436\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [16:23<00:00, 39.35s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nğŸ“Š INFERENCE SUMMARY\nTotal Questions Processed: 25, Correct Guesses: 15\nAccuracy: 60.00%\nImages per Second: 0.03 img/s\nResults for this batch saved to: train_inference_results.csv\n\nğŸ‰ Inference completed! Check train_inference_results.csv for detailed results.\nğŸ§¹ Cleaning up VRAM...\nVRAM cleaned up\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===================================================================\n# Block 5: Post-Inference Analysis (NEW)\n# ===================================================================\nimport pandas as pd\n\ntry:\n    # Load the results from the training run\n    output_csv = \"train_inference_results.csv\"\n    df = pd.read_csv(output_csv)\n\n    print(f\"\\n--- Analysis of {output_csv} ---\")\n\n    # Display a count of the model's answers vs correct answers\n    print(\"\\nModel answer distribution:\")\n    print(df['model_answer'].value_counts())\n    print(\"\\nCorrect answer distribution:\")\n    print(df['correct_answer'].value_counts())\n\n    # The 'is_correct' column is already calculated during inference.\n    # We can directly calculate the accuracy from it.\n    if 'is_correct' in df.columns and not df['is_correct'].isnull().all():\n        # Ensure boolean type for correct calculation, handling potential non-boolean values\n        df['is_correct'] = df['is_correct'].astype(bool)\n        accuracy = df['is_correct'].mean() * 100\n        print(f\"\\nâœ… Final Accuracy on the processed training set slice: {accuracy:.2f}%\")\n        \n        # Display rows where the model was incorrect\n        print(\"\\nğŸ” Examples of incorrect answers:\")\n        incorrect_df = df[df['is_correct'] == False]\n        print(incorrect_df[['question_id', 'correct_answer', 'model_answer', 'reasoning']].head())\n\n    else:\n        print(\"\\n'is_correct' column not found or is empty. Cannot calculate accuracy.\")\n\nexcept FileNotFoundError:\n    print(f\"\\nCould not find the results file: {output_csv}. Please run the main inference block first.\")","metadata":{"_uuid":"705436a1-e806-4050-8a0c-b512b2b2d8f5","_cell_guid":"426040b3-607b-447d-b94e-2a61128dd3a2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T15:11:39.918306Z","iopub.execute_input":"2025-08-31T15:11:39.918524Z","iopub.status.idle":"2025-08-31T15:11:39.980179Z","shell.execute_reply.started":"2025-08-31T15:11:39.918506Z","shell.execute_reply":"2025-08-31T15:11:39.979558Z"}},"outputs":[{"name":"stdout","text":"\n--- Analysis of train_inference_results.csv ---\n\nModel answer distribution:\nmodel_answer\nA        11\nFalse     5\nB         4\nC         3\nD         1\nTrue      1\nName: count, dtype: int64\n\nCorrect answer distribution:\ncorrect_answer\nA        9\nB        6\nÄuÌng    4\nC        3\nSai      2\nD        1\nName: count, dtype: int64\n\nâœ… Final Accuracy on the processed training set slice: 60.00%\n\nğŸ” Examples of incorrect answers:\n  question_id correct_answer model_answer  \\\n0     train_1              B            A   \n4     train_5              B            A   \n7     train_8          ÄuÌng        False   \n8     train_9          ÄuÌng        False   \n9    train_10            Sai        False   \n\n                                           reasoning  \n0  Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i\\n- CÃ¢u há»i yÃªu cáº§u t...  \n4  Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i: CÃ¢u há»i yÃªu cáº§u phÃ¢...  \n7  Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i\\n- CÃ¢u há»i yÃªu cáº§u x...  \n8  Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i\\n- CÃ¢u há»i yÃªu cáº§u x...  \n9  Step 1: PhÃ¢n tÃ­ch cÃ¢u há»i\\n- CÃ¢u há»i yÃªu cáº§u x...  \n","output_type":"stream"}],"execution_count":8}]}