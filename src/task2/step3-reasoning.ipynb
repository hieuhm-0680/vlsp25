{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12847885,"sourceType":"datasetVersion","datasetId":8083039},{"sourceId":12851054,"sourceType":"datasetVersion","datasetId":8128075},{"sourceId":259171175,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Do this only in Colab notebooks! Otherwise use pip install unsloth\n!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo -q\n!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer -q\n!pip install --no-deps unsloth -q","metadata":{"_uuid":"b7e3038a-5414-472a-965d-747b18da57ef","_cell_guid":"363d34eb-2b89-47a9-baae-d8aedc823a83","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:53:25.331716Z","iopub.execute_input":"2025-08-31T14:53:25.331981Z","iopub.status.idle":"2025-08-31T14:53:40.544760Z","shell.execute_reply.started":"2025-08-31T14:53:25.331951Z","shell.execute_reply":"2025-08-31T14:53:40.544099Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nunsloth-zoo 2025.8.9 requires msgspec, which is not installed.\nunsloth-zoo 2025.8.9 requires tyro, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport gc\nimport json\nimport os\nfrom PIL import Image\nfrom unsloth import FastVisionModel\nfrom typing import Union, Dict, List, Optional\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport time","metadata":{"_uuid":"b933272b-e8c2-47d1-80f0-b976a7048339","_cell_guid":"8047e548-5db7-44c2-8b8e-bddc1392e815","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:53:40.545602Z","iopub.execute_input":"2025-08-31T14:53:40.545797Z","iopub.status.idle":"2025-08-31T14:54:33.018310Z","shell.execute_reply.started":"2025-08-31T14:53:40.545774Z","shell.execute_reply":"2025-08-31T14:54:33.017501Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-08-31 14:53:58.914509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756652039.244777      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756652039.339965      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===================================================================\n# Block 1: Data Loading and Utility Functions (MODIFIED FOR TRAIN SET)\n# ===================================================================\n\nimport json\nimport os\nimport re\nfrom PIL import Image\n\ndef load_train_data() -> tuple:\n    \"\"\"\n    Load all training data, law DB, and pre-extracted article details.\n    The 'answer' is already included in the training JSON.\n    \"\"\"\n    train_json_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/vlsp_2025_train.json\"\n    law_db_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/law_db/vlsp2025_law_new.json\"\n    extracted_data_path = \"/kaggle/input/vlsp-summarize-final/train_vision_rule_extraction_results.csv\"\n\n    print(f\"Loading training data from: {train_json_path}\")\n    print(f\"Loading law database from: {law_db_path}\")\n    print(f\"Loading extracted article data from: {extracted_data_path}\")\n\n    with open(train_json_path, 'r', encoding='utf-8') as f:\n        # Training data already contains the answer key for all items\n        train_questions = json.load(f)\n    with open(law_db_path, 'r', encoding='utf-8') as f:\n        law_database = json.load(f)\n\n    extracted_data_df = pd.read_csv(extracted_data_path)\n\n    print(f\"Loaded {len(train_questions)} total training questions.\")\n    print(f\"Loaded {len(law_database)} laws in database.\")\n    print(f\"Loaded {len(extracted_data_df)} rows from extracted data CSV.\")\n    \n    return train_questions, law_database, extracted_data_df\n\n\ndef get_relevant_articles(question_data: dict, law_database: list) -> list:\n    \"\"\"\n    Extract relevant articles for a given question from the raw law database.\n    \"\"\"\n    relevant_articles = []\n    for ref_article in question_data.get(\"relevant_articles\", []):\n        law_id, article_id = ref_article[\"law_id\"], ref_article[\"article_id\"]\n        for law in law_database:\n            if law[\"id\"] == law_id:\n                for article in law[\"articles\"]:\n                    if article[\"id\"] == article_id:\n                        relevant_articles.append({\n                            \"law_id\": law_id, \"law_title\": law[\"title\"], \"article_id\": article[\"id\"],\n                            \"article_title\": article[\"title\"], \"article_text\": article[\"text\"]\n                        })\n                        break\n                break\n    return relevant_articles\n\n\ndef clean_article_text(text: str) -> str:\n    \"\"\"\n    Clean article text by removing image and table tags.\n    \"\"\"\n    clean_text = re.sub(r'<<IMAGE: (.*?) /IMAGE>>', '', text)\n    return re.sub(r'<<TABLE: (.*?) /TABLE>>', '', clean_text, flags=re.DOTALL).strip()\n\n\ndef resize_image_if_needed(image_path: str, threshold: int = 768) -> Image.Image:\n    \"\"\"\n    Loads an image and resizes it proportionally if either dimension exceeds the threshold.\n    \"\"\"\n    img = Image.open(image_path).convert(\"RGB\")\n    return img","metadata":{"_uuid":"4869941d-df8a-4b7d-a1b9-55afe7b1d347","_cell_guid":"94552239-2867-479c-86c0-107501d1bc9b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.020061Z","iopub.execute_input":"2025-08-31T14:54:33.020325Z","iopub.status.idle":"2025-08-31T14:54:33.028932Z","shell.execute_reply.started":"2025-08-31T14:54:33.020306Z","shell.execute_reply":"2025-08-31T14:54:33.028206Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ===================================================================\n# Block 2: Prompt Generation and Processing (ADJUSTED FOR NEW EXTRACTION)\n# ===================================================================\n\ndef make_prompt(\n    question_id: str,\n    question: str,\n    choices: Optional[Dict[str, str]],\n    question_type: str,\n    relevant_articles: List[dict], # Used only for the fallback mechanism\n    extracted_data_df: pd.DataFrame\n) -> str:\n    \"\"\"\n    Creates a formatted CoT prompt using pre-extracted data (one entry per question)\n    with a fallback to the raw law DB.\n    \"\"\"\n    prompt_parts = [\"Bạn là một chuyên gia về luật giao thông Việt Nam. Hãy trả lời câu hỏi sau dựa trên các điều luật được cung cấp.\\n\"]\n\n    if question_type == \"Multiple choice\":\n        extend_2 = \"Phân tích luật, câu hỏi và lần lượt phân tích cả A, B, C và D. Giải thích tại sao câu trả lời cuối cùng là đúng, và các câu trả lời còn lại là sai\"\n        step_4 = \"Step 3: [Duyệt qua và phân tích cả A, B, C và D.]\"\n    else: # Yes/No\n        extend_2 = \"Phân tích luật và câu hỏi, phân tích cho cả hai hướng là câu trả lời sai và câu trả lời đúng.\"\n        step_4 = \"Step 3: [Chú ý xác định đây là mệnh đề khẳng định hay phủ định.]\"\n        \n    prompt_parts.extend([\n        \"\\n# INSTRUCTION\",\n        \"Hãy suy nghĩ từng bước và trả lời theo định dạng yêu cầu:\",\n        extend_2,\n    ])\n    \n    question_extraction = extracted_data_df[extracted_data_df['question_id'] == question_id]\n\n    prompt_parts.append(\"\\n# BIỂN BÁO TRONG ẢNH:\")\n    \n    use_fallback = True\n    if not question_extraction.empty:\n        row = question_extraction.iloc[0]\n        # The training extraction script uses 'raw' which contains all details\n        raw_extraction = row.get('raw')\n        if pd.notna(raw_extraction) and \"error\" not in str(raw_extraction).lower():\n            prompt_parts.append(raw_extraction)\n            use_fallback = False\n\n    # --- FALLBACK LOGIC ---\n    if use_fallback:\n        print(f\"  -> NOTE: Using fallback for question {question_id}. No valid extraction found.\")\n        article_count = 0\n        \n        for article in relevant_articles:\n            article_text = clean_article_text(article['article_text'])\n            text_snippet = \" \".join(article_text.split()[:100])\n            if len(article_text.split()) > 100:\n                text_snippet += \"...\"\n\n            prompt_parts.extend([\n                f\"## Tên: {article['article_title']}\",\n                f\"Nội dung: {text_snippet}\",\n                \"\"\n            ])\n            article_count += 1\n        \n        if article_count == 0: \n            prompt_parts.append(\"Không tìm thấy thông tin luật liên quan.\")\n\n    general_knowledge = \"\"\"# EXCEPTION\nKhông chịu tác động của biển báo: xe cấp cứu, xe cảnh sát, xe ưu tiên.\"\"\"\n    prompt_parts.append(general_knowledge)\n        \n    prompt_parts.extend([\n        \"\\n# ĐỊNH DẠNG OUTPUT\",\n        \"Cung cấp câu trả lời cuối cùng theo định dạng sau, không thêm bất kỳ văn bản nào khác:\",\n        \"<reasoning>\",\n        \"Step 1: [Phân tích câu hỏi]\",\n        \"Step 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\",\n        step_4,\n        \"</reasoning>\",\n    ])\n\n    if question_type == \"Multiple choice\":\n        prompt_parts.append(\"<answer>Chỉ một chữ cái (A, B, C, hoặc D)</answer>\")\n    else: # Yes/No\n        prompt_parts.append(\"<answer>Chỉ 'True' hoặc 'False'</answer>\")\n\n    prompt_parts.extend([\"# CÂU HỎI:\", f\"{question}\\n\"])\n\n    if question_type == \"Multiple choice\" and choices:\n        prompt_parts.append(\"# CÁC LỰA CHỌN:\")\n        for key, value in choices.items():\n            prompt_parts.append(f\"<{key}>{value}</{key}>\")\n\n    prompt_parts.append(\"# OUTPUT\")\n    return \"\\n\".join(prompt_parts)\n\n\ndef get_train_image_path(image_id: str) -> str:\n    \"\"\"\n    Get the full path to a training image.\n    \"\"\"\n    base_path = \"/kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/train_images/train_images\"\n    image_filename = f\"{image_id}.jpg\"\n    \n    image_path = os.path.join(base_path, image_filename)\n    if not os.path.exists(image_path):\n        image_path = image_path.replace(\".jpg\", \".png\")\n    return image_path\n\n\ndef process_train_question(question_data: dict, law_database: list, extracted_data_df: pd.DataFrame) -> tuple:\n    \"\"\"\n    Process a single training question to get prompt, image path, and answer.\n    \"\"\"\n    prompt = make_prompt(\n        question_id=question_data[\"id\"],\n        question=question_data[\"question\"],\n        choices=question_data.get(\"choices\"),\n        question_type=question_data[\"question_type\"],\n        relevant_articles=get_relevant_articles(question_data, law_database),\n        extracted_data_df=extracted_data_df\n    )\n    image_path = get_train_image_path(question_data[\"image_id\"])\n    return prompt, image_path, question_data.get(\"answer\"), question_data[\"id\"]","metadata":{"_uuid":"db3e8eb8-b945-4a06-9851-bfe7a408c674","_cell_guid":"f97fe3b5-14b9-4da7-9906-4952cf37388e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.029751Z","iopub.execute_input":"2025-08-31T14:54:33.030005Z","iopub.status.idle":"2025-08-31T14:54:33.065580Z","shell.execute_reply.started":"2025-08-31T14:54:33.029983Z","shell.execute_reply":"2025-08-31T14:54:33.065001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ===================================================================\n# Block 3: Inference Class (UNCHANGED)\n# ===================================================================\n\nclass SimpleVisionInference:\n    \"\"\"Simple 2-GPU vision model inference using Unsloth.\"\"\"\n    def __init__(self, model_name: str = \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\"):\n        self.model, self.processor = None, None\n        self.model_name = model_name\n        print(f\"Available GPUs: {torch.cuda.device_count()}\")\n        device_map = \"balanced\" if torch.cuda.device_count() >= 2 else \"auto\"\n        print(f\"Loading model from: {model_name} with device_map: {device_map}\")\n        self._load_model(device_map)\n        print(\"Model loaded successfully!\")\n\n    def _load_model(self, device_map: str):\n        try:\n            self.model, self.processor = FastVisionModel.from_pretrained(\n                self.model_name, load_in_4bit=True, device_map=device_map\n            )\n            FastVisionModel.for_inference(self.model)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model {self.model_name}: {str(e)}\")\n\n    def inference(self, prompt: str, image_path: str, max_new_tokens: int = 8, **kwargs) -> str:\n        \"\"\"\n        Perform inference, now with integrated resizing and logging.\n        \"\"\"\n        try:\n            pil_image = resize_image_if_needed(image_path, threshold=768)\n            print(f\"\\nLOG: Processing Image '{os.path.basename(image_path)}'\")\n            print(f\"  Image Size (for Inference): {pil_image.size} | Prompt Chars: {len(prompt)}\")\n            device = next(self.model.parameters()).device\n            messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": prompt}]}]\n            text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            inputs = self.processor(text=[text], images=[pil_image], return_tensors=\"pt\").to(device)\n            with torch.no_grad():\n                outputs = self.model.generate(\n                    **inputs,\n                    max_new_tokens=max_new_tokens,\n                    use_cache=True,\n                    temperature=0.1\n                )\n            return self.processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0].strip()\n        except Exception as e:\n            raise RuntimeError(f\"Inference failed: {str(e)}\")\n\n    def cleanup(self):\n        \"\"\"Clean up VRAM.\"\"\"\n        print(\"🧹 Cleaning up VRAM...\")\n        del self.model\n        del self.processor\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        print(\"VRAM cleaned up\")\n\n    def __del__(self):\n        self.cleanup()","metadata":{"_uuid":"a75a815f-870d-4a4b-8e4f-20928f7e964e","_cell_guid":"6d1e9973-99e2-4582-8e9f-c7f7896110d9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.066511Z","iopub.execute_input":"2025-08-31T14:54:33.066681Z","iopub.status.idle":"2025-08-31T14:54:33.085274Z","shell.execute_reply.started":"2025-08-31T14:54:33.066668Z","shell.execute_reply":"2025-08-31T14:54:33.084707Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ===================================================================\n# Block 4: Full Dataset Inference Workflow (MODIFIED FOR TRAIN SET)\n# ===================================================================\n\ndef parse_cot_output(raw_output: str) -> (str, str):\n    \"\"\"\n    Parses the CoT output to extract reasoning and the final answer.\n    \"\"\"\n    reasoning_match = re.search(r\"<reasoning>(.*?)</reasoning>\", raw_output, re.DOTALL)\n    answer_match = re.search(r\"<answer>(.*?)</answer>\", raw_output, re.DOTALL)\n    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"No reasoning found.\"\n    answer = answer_match.group(1).strip() if answer_match else \"No answer found.\"\n    if(reasoning == \"No reasoning found.\"):\n        print(raw_output)\n    return reasoning, answer\n\ndef inference_all_questions(model_instance: SimpleVisionInference, questions: list, law_database: list, extracted_data_df: pd.DataFrame, output_csv: str):\n    \"\"\"\n    Run CoT inference on all training questions, evaluate, log periodically, and save results.\n    \"\"\"\n    results = []\n    correct_count, total_processed = 0, 0\n    start_time = time.time()\n    answer_map = {\"Yes\": \"True\", \"No\": \"False\"}\n\n    PROMPT_SANITY_CHECK_COUNT = 3\n\n    if not questions:\n        print(\"No questions to process.\")\n        return\n    print(f\"\\n🔄 Running inference on a batch of {len(questions)} questions (from ID '{questions[0]['id']}' to '{questions[-1]['id']}')...\")\n    \n    for index, question_data in enumerate(tqdm(questions, desc=\"Processing Questions\")):\n        result_record = {\n            'question_id': question_data['id'],\n            'correct_answer': question_data.get('answer'),\n            'reasoning': '',\n            'model_answer': '',\n            'is_correct': False\n        }\n        \n        try:\n            prompt, image_path, correct_answer, _ = process_train_question(\n                question_data, law_database, extracted_data_df\n            )\n            \n            if index < PROMPT_SANITY_CHECK_COUNT:\n                print(f\"\\n--- PROMPT SANITY CHECK (Question: {question_data['id']}) ---\")\n                print(prompt)\n                print(\"--------------------------------------------------\")\n\n            if os.path.exists(image_path):\n                raw_model_output = model_instance.inference(prompt, image_path, max_new_tokens=1024)\n                reasoning, final_answer = parse_cot_output(raw_model_output)\n                \n                if index < PROMPT_SANITY_CHECK_COUNT:\n                    print(f\"\\n--- Sanity Check (Question: {question_data['id']}) ---\")\n                    print(f\"  Reasoning: {reasoning}\")\n                    print(f\"  Model Answer: {final_answer} | Correct Answer: {correct_answer}\")\n                    print(\"-------------------------------------------------\")\n\n                is_correct = False\n                if question_data['question_type'] == \"Yes/No\":\n                    if final_answer == answer_map.get(correct_answer):\n                        is_correct = True\n                else: # Handles \"Multiple choice\"\n                    if final_answer == correct_answer:\n                        is_correct = True\n                \n                if is_correct:\n                    correct_count += 1\n\n                result_record.update({\n                    'reasoning': reasoning,\n                    'model_answer': final_answer,\n                    'is_correct': is_correct\n                })\n                total_processed += 1\n            else:\n                result_record['model_answer'] = \"ERROR: Image not found\"\n                print(f\"  Skipping {question_data['id']}: Image not found at {image_path}\")\n                \n        except Exception as e:\n            result_record['model_answer'] = f\"ERROR: {e}\"\n            print(f\"\\n  ❌ Error processing question {question_data['id']}: {e}\")\n        \n        results.append(result_record)\n\n    df = pd.DataFrame(results)\n    df.to_csv(output_csv, index=False, encoding='utf-8')\n    total_time = time.time() - start_time\n    accuracy = (correct_count / total_processed * 100) if total_processed > 0 else 0\n    \n    print(\"\\n\" + \"=\"*50 + \"\\n📊 INFERENCE SUMMARY\")\n    print(f\"Total Questions Processed: {total_processed}, Correct Guesses: {correct_count}\")\n    print(f\"Accuracy: {accuracy:.2f}%\")\n    if total_time > 0:\n        print(f\"Images per Second: {total_processed / total_time:.2f} img/s\")\n    print(f\"Results for this batch saved to: {output_csv}\")","metadata":{"_uuid":"a5e3ed92-1177-403a-a306-2975d8b16bb6","_cell_guid":"f1092391-2da3-43f3-9d6b-445a363375a2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T14:54:33.086039Z","iopub.execute_input":"2025-08-31T14:54:33.086302Z","iopub.status.idle":"2025-08-31T14:54:33.107720Z","shell.execute_reply.started":"2025-08-31T14:54:33.086279Z","shell.execute_reply":"2025-08-31T14:54:33.107209Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- MODIFIED: Main function now handles the training data ---\ndef main():\n    \"\"\"\n    Main function for running inference on the training set.\n    \"\"\"\n    print(\"🚀 Vietnamese Law QA System - Training Set Inference\")\n    print(\"=\" * 70)\n\n    output_csv = \"train_inference_results.csv\"\n    model_instance = None\n    try:\n        print(\"📚 Loading Vietnamese Law Training Dataset and Extracted Data...\")\n        train_questions, law_database, extracted_data_df = load_train_data()\n\n        print(\"\\n🤖 Initializing Qwen2.5-VL Model...\")\n        model_instance = SimpleVisionInference()\n\n        inference_all_questions(\n            model_instance=model_instance,\n            questions=train_questions[:25], # Using a slice for initial testing\n            law_database=law_database,\n            extracted_data_df=extracted_data_df,\n            output_csv=output_csv\n        )\n\n        print(f\"\\n🎉 Inference completed! Check {output_csv} for detailed results.\")\n\n    except Exception as e:\n        print(f\"❌ A critical error occurred: {e}\")\n        import traceback\n        traceback.print_exc()\n\n    finally:\n        if model_instance:\n            del model_instance\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"95b27ce7-5c24-4d24-bf8b-75d0fa97a768","_cell_guid":"3b13d338-2474-4885-8bf6-d2d34ef1d4c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-31T14:54:33.108554Z","iopub.execute_input":"2025-08-31T14:54:33.108782Z","iopub.status.idle":"2025-08-31T15:11:39.910494Z","shell.execute_reply.started":"2025-08-31T14:54:33.108756Z","shell.execute_reply":"2025-08-31T15:11:39.909829Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"🚀 Vietnamese Law QA System - Training Set Inference\n======================================================================\n📚 Loading Vietnamese Law Training Dataset and Extracted Data...\nLoading training data from: /kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/train_data/vlsp_2025_train.json\nLoading law database from: /kaggle/input/vlsp-dataset/VLSP 2025 - MLQA-TSR Data Release-20250820T023346Z-1-001/VLSP 2025 - MLQA-TSR Data Release/law_db/vlsp2025_law_new.json\nLoading extracted article data from: /kaggle/input/vlsp-summarize-final/train_vision_rule_extraction_results.csv\nLoaded 530 total training questions.\nLoaded 2 laws in database.\nLoaded 441 rows from extracted data CSV.\n\n🤖 Initializing Qwen2.5-VL Model...\nAvailable GPUs: 2\nLoading model from: unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit with device_map: balanced\n==((====))==  Unsloth 2025.8.10: Fast Qwen2_5_Vl patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8538bb9f0b194a3eb1046a1ded46eb51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be8ec4f9818049a1b5363f69a6827047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b506770644c946e3ad9438b7f094f545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b9f1f135a77435baebdba9506ce0a1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3278350719a54d08b815f56046439447"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef88ac043c9470cb870baa6e52f370d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e08998e8d54dbdae06bd1f39562cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38883b79c35f4efb86159645d9f3d62e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e4ea30e59e340aa9c029e5edb60cfa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211ac934326045baa7eeda2e1580be12"}},"metadata":{}},{"name":"stderr","text":"You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a08ee15545e4c0c8ec6a2760e75f596"}},"metadata":{}},{"name":"stdout","text":"Model loaded successfully!\n\n🔄 Running inference on a batch of 25 questions (from ID 'train_1' to 'train_25')...\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   0%|          | 0/25 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_1. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_1) ---\nBạn là một chuyên gia về luật giao thông Việt Nam. Hãy trả lời câu hỏi sau dựa trên các điều luật được cung cấp.\n\n\n# INSTRUCTION\nHãy suy nghĩ từng bước và trả lời theo định dạng yêu cầu:\nPhân tích luật, câu hỏi và lần lượt phân tích cả A, B, C và D. Giải thích tại sao câu trả lời cuối cùng là đúng, và các câu trả lời còn lại là sai\n\n# BIỂN BÁO TRONG ẢNH:\n## Tên: Ý nghĩa sử dụng các biển báo cấm\nNội dung: 22.1. Biển báo cấm có mã P (cấm) và DP (hết cấm) với tên các biển như sau: - Biển số P.101: Đường cấm; - Biển số P.102: Cấm đi ngược chiều; - Biển số P.103a: Cấm xe ô tô; - Biển số P.103(b,c): Cấm xe ô tô rẽ trái; Cấm xe ôtô rẽ phải; - Biển số P.104: Cấm xe máy; - Biển số P.105: Cấm xe ô tô và xe máy; - Biển số P.106(a,b): Cấm xe ô tô tải; - Biển số P.106c: Cấm các xe chở hàng nguy hiểm; - Biển số P.107: Cấm xe ô...\n\n# EXCEPTION\nKhông chịu tác động của biển báo: xe cấp cứu, xe cảnh sát, xe ưu tiên.\n\n# ĐỊNH DẠNG OUTPUT\nCung cấp câu trả lời cuối cùng theo định dạng sau, không thêm bất kỳ văn bản nào khác:\n<reasoning>\nStep 1: [Phân tích câu hỏi]\nStep 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\nStep 3: [Duyệt qua và phân tích cả A, B, C và D.]\n</reasoning>\n<answer>Chỉ một chữ cái (A, B, C, hoặc D)</answer>\n# CÂU HỎI:\nBiển báo cấm xe khách trên 29 chỗ được áp dụng trong các khoảng thời gian nào? \n\n# CÁC LỰA CHỌN:\n<A>Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này không được phép lưu thông.</A>\n<B>Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này được phép lưu thông.</B>\n<C>Cấm lưu thông cả ngày.</C>\n<D>D. Không cấm xe khách trên 29 chỗ lưu thông.</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1616\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   4%|▍         | 1/25 [01:26<34:32, 86.34s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_1) ---\n  Reasoning: Step 1: Phân tích câu hỏi\n- Câu hỏi yêu cầu tìm hiểu thời gian áp dụng của biển báo cấm xe khách trên 29 chỗ.\n\nStep 2: Phân tích # BIỂN BÁO TRONG ẢNH\n- Biển báo cấm xe khách trên 29 chỗ có hình dạng là một hình tròn đỏ với biểu tượng xe khách bị chấm xanh, kèm theo đó là một biển phụ thông báo thời gian áp dụng.\n- Thời gian cụ thể được ghi rõ trên biển phụ là từ 06:30 đến 08:00 và từ 16:30 đến 18:30.\n\nStep 3: Duyệt qua và phân tích cả A, B, C và D.\n- A: \"Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này không được phép lưu thông.\" - Đây là đáp án chính xác vì nó trùng khớp hoàn toàn với thông tin trên biển phụ.\n- B: \"Từ 6:30 đến 8:00 và từ 16:30 đến 18:30; ngoài các khoảng thời gian này được phép lưu thông.\" - Đây là đáp án sai vì nó trái ngược với thông tin trên biển phụ.\n- C: \"Cấm lưu thông cả ngày.\" - Đây là đáp án sai vì chỉ có hai khoảng thời gian cụ thể được cấm, không phải cả ngày.\n- D: \"D. Không cấm xe khách trên 29 chỗ lưu thông.\" - Đây là đáp án sai vì biển báo đã明确规定禁止特定车辆在特定时间段内通行。\n  Model Answer: A | Correct Answer: B\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_2. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_2) ---\nBạn là một chuyên gia về luật giao thông Việt Nam. Hãy trả lời câu hỏi sau dựa trên các điều luật được cung cấp.\n\n\n# INSTRUCTION\nHãy suy nghĩ từng bước và trả lời theo định dạng yêu cầu:\nPhân tích luật, câu hỏi và lần lượt phân tích cả A, B, C và D. Giải thích tại sao câu trả lời cuối cùng là đúng, và các câu trả lời còn lại là sai\n\n# BIỂN BÁO TRONG ẢNH:\n## Tên: Vị trí đặt biển báo cấm theo chiều đi và hướng hiệu lực của biển\nNội dung: 26.1. Biển báo cấm được đặt ở nơi đường giao nhau hoặc trước một vị trí trên đường cần cấm. Biển có hiệu lực bắt đầu từ vị trí đặt biển trở đi. Nếu vì lý do nào đó, biển đặt cách xa vị trí định cấm thì phải đặt biển phụ số S.502 để chỉ rõ khoảng cách từ sau biển cấm đến vị trí biển bắt đầu có hiệu lực. 26.2. Khi cần thiết để chỉ rõ hướng tác dụng của biển và chỉ vị trí bắt đầu hay vị trí kết thúc hiệu lực của biển phải...\n\n## Tên: Biển báo giao thông có thông tin thay đổi, biển báo tạm thời\nNội dung: 14.1. Biển báo giao thông có thông tin thay đổi (biển báo VMS): là biển báo điện tử có thể thay đổi thông tin trên cùng một mặt biển. Biển được sử dụng khi thông tin hiển thị trên biển báo cần phải thay đổi tùy theo tình huống giao thông. Tùy theo mục đích, thông tin trên biển có thể là chỉ dẫn, cấm, hiệu lệnh hoặc báo nguy hiểm và cảnh báo. Biển không được dùng để quảng cáo, sử dụng hình hoạt họa, nhấp nháy, các hình có tính chất di chuyển. Khi ở một vị trí...\n\n# EXCEPTION\nKhông chịu tác động của biển báo: xe cấp cứu, xe cảnh sát, xe ưu tiên.\n\n# ĐỊNH DẠNG OUTPUT\nCung cấp câu trả lời cuối cùng theo định dạng sau, không thêm bất kỳ văn bản nào khác:\n<reasoning>\nStep 1: [Phân tích câu hỏi]\nStep 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\nStep 3: [Duyệt qua và phân tích cả A, B, C và D.]\n</reasoning>\n<answer>Chỉ một chữ cái (A, B, C, hoặc D)</answer>\n# CÂU HỎI:\nNhững loại phương tiện nào bị cấm trên đoạn đường này\n\n# CÁC LỰA CHỌN:\n<A>Xe khách trên 29 chỗ</A>\n<B>ô tô con</B>\n<C>Xe máy</C>\n<D>Xe đạp</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1973\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:   8%|▊         | 2/25 [02:00<21:22, 55.75s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_2) ---\n  Reasoning: Step 1: [Phân tích câu hỏi]\nCâu hỏi yêu cầu xác định những loại phương tiện nào bị cấm trên đoạn đường này. \n\nStep 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\nBiển báo cấm xe khách trên 29 chỗ được đặt ở vị trí đường giao nhau hoặc trước vị trí cần cấm. Biển có hiệu lực bắt đầu từ vị trí đặt biển trở đi. Thông tin trên biển cho biết thời gian cấm từ 06:30-08:00 và 16:30-18:30.\n\nStep 3: [Duyệt qua và phân tích cả A, B, C và D.]\n- A: Xe khách trên 29 chỗ - Đây chính là thông tin được hiển thị trên biển báo cấm.\n- B: ô tô con - Không có thông tin nào trên biển báo cấm về việc cấm ô tô con.\n- C: Xe máy - Không có thông tin nào trên biển báo cấm về việc cấm xe máy.\n- D: Xe đạp - Không có thông tin nào trên biển báo cấm về việc cấm xe đạp.\n  Model Answer: A | Correct Answer: A\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_3. No valid extraction found.\n\n--- PROMPT SANITY CHECK (Question: train_3) ---\nBạn là một chuyên gia về luật giao thông Việt Nam. Hãy trả lời câu hỏi sau dựa trên các điều luật được cung cấp.\n\n\n# INSTRUCTION\nHãy suy nghĩ từng bước và trả lời theo định dạng yêu cầu:\nPhân tích luật, câu hỏi và lần lượt phân tích cả A, B, C và D. Giải thích tại sao câu trả lời cuối cùng là đúng, và các câu trả lời còn lại là sai\n\n# BIỂN BÁO TRONG ẢNH:\n## Tên: Vị trí đặt biển báo cấm theo chiều đi và hướng hiệu lực của biển\nNội dung: 26.1. Biển báo cấm được đặt ở nơi đường giao nhau hoặc trước một vị trí trên đường cần cấm. Biển có hiệu lực bắt đầu từ vị trí đặt biển trở đi. Nếu vì lý do nào đó, biển đặt cách xa vị trí định cấm thì phải đặt biển phụ số S.502 để chỉ rõ khoảng cách từ sau biển cấm đến vị trí biển bắt đầu có hiệu lực. 26.2. Khi cần thiết để chỉ rõ hướng tác dụng của biển và chỉ vị trí bắt đầu hay vị trí kết thúc hiệu lực của biển phải...\n\n# EXCEPTION\nKhông chịu tác động của biển báo: xe cấp cứu, xe cảnh sát, xe ưu tiên.\n\n# ĐỊNH DẠNG OUTPUT\nCung cấp câu trả lời cuối cùng theo định dạng sau, không thêm bất kỳ văn bản nào khác:\n<reasoning>\nStep 1: [Phân tích câu hỏi]\nStep 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\nStep 3: [Duyệt qua và phân tích cả A, B, C và D.]\n</reasoning>\n<answer>Chỉ một chữ cái (A, B, C, hoặc D)</answer>\n# CÂU HỎI:\nThời gian cấm xe khách trên 29 chỗ có bị thay đổi theo mùa không?\n\n# CÁC LỰA CHỌN:\n<A>Thời gian cấm xe khách thay đổi vào mùa hè và mùa đông</A>\n<B>Thời gian cấm xe khách thay đổi vào các ngày lễ, Tết</B>\n<C>Thời gian cấm xe khách cố định, không thay đổi theo mùa</C>\n<D>Thời gian cấm xe khách chỉ áp dụng vào giờ cao điểm buổi sáng</D>\n# OUTPUT\n--------------------------------------------------\n\nLOG: Processing Image 'train_1_3.jpg'\n  Image Size (for Inference): (1200, 900) | Prompt Chars: 1608\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  12%|█▏        | 3/25 [02:41<17:56, 48.95s/it]","output_type":"stream"},{"name":"stdout","text":"\n--- Sanity Check (Question: train_3) ---\n  Reasoning: Step 1: [Phân tích câu hỏi] \nCâu hỏi hỏi về việc thời gian cấm xe khách trên 29 chỗ có thay đổi theo mùa hay không. \n\nStep 2: [Phân tích # BIỂN BÁO TRONG ẢNH]\nBiển báo trong ảnh chỉ ra thời gian cụ thể từ 06:30-08:00 và 16:30-18:30 hàng ngày. Không có thông tin gì về việc thời gian này thay đổi theo mùa.\n\nStep 3: [Duyệt qua và phân tích cả A, B, C và D.]\n- A: Thời gian cấm xe khách thay đổi vào mùa hè và mùa đông - Không có thông tin nào cho thấy thời gian này thay đổi theo mùa.\n- B: Thời gian cấm xe khách thay đổi vào các ngày lễ, Tết - Không có thông tin nào cho thấy thời gian này thay đổi theo các ngày lễ, Tết.\n- C: Thời gian cấm xe khách cố định, không thay đổi theo mùa - Đây là lựa chọn phù hợp với thông tin trên biển báo.\n- D: Thời gian cấm xe khách chỉ áp dụng vào giờ cao điểm buổi sáng - Thời gian trên biển báo không chỉ áp dụng vào giờ cao điểm buổi sáng mà còn bao gồm cả buổi chiều.\n\nVì vậy, câu trả lời cuối cùng là đúng là C.\n  Model Answer: C | Correct Answer: C\n-------------------------------------------------\n  -> NOTE: Using fallback for question train_4. No valid extraction found.\n\nLOG: Processing Image 'train_1_20.jpg'\n  Image Size (for Inference): (500, 334) | Prompt Chars: 1828\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  16%|█▌        | 4/25 [03:32<17:22, 49.65s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_5. No valid extraction found.\n\nLOG: Processing Image 'train_1_10.jpg'\n  Image Size (for Inference): (1200, 1200) | Prompt Chars: 2245\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  20%|██        | 5/25 [04:19<16:16, 48.81s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_6. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 1833\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  24%|██▍       | 6/25 [05:03<14:58, 47.31s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_7. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 2446\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  28%|██▊       | 7/25 [05:52<14:16, 47.60s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_8. No valid extraction found.\n\nLOG: Processing Image 'train_1_18.jpg'\n  Image Size (for Inference): (750, 500) | Prompt Chars: 2045\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  32%|███▏      | 8/25 [06:16<11:24, 40.29s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_9. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1377\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  36%|███▌      | 9/25 [06:47<09:57, 37.36s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_10. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1391\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  40%|████      | 10/25 [07:16<08:42, 34.84s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_11. No valid extraction found.\n\nLOG: Processing Image 'train_1_12.jpg'\n  Image Size (for Inference): (1200, 1800) | Prompt Chars: 1781\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  44%|████▍     | 11/25 [08:02<08:55, 38.25s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_12. No valid extraction found.\n\nLOG: Processing Image 'train_1_6.jpg'\n  Image Size (for Inference): (600, 600) | Prompt Chars: 1415\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  48%|████▊     | 12/25 [08:43<08:26, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_13. No valid extraction found.\n\nLOG: Processing Image 'train_1_6.jpg'\n  Image Size (for Inference): (600, 600) | Prompt Chars: 1746\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  52%|█████▏    | 13/25 [09:25<07:56, 39.75s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_14. No valid extraction found.\n\nLOG: Processing Image 'train_1_17.jpg'\n  Image Size (for Inference): (731, 487) | Prompt Chars: 1476\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  56%|█████▌    | 14/25 [10:11<07:40, 41.84s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_15. No valid extraction found.\n\nLOG: Processing Image 'train_1_17.jpg'\n  Image Size (for Inference): (731, 487) | Prompt Chars: 1398\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  60%|██████    | 15/25 [10:56<07:06, 42.70s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_16. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1613\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  64%|██████▍   | 16/25 [11:38<06:21, 42.39s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_17. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1307\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  68%|██████▊   | 17/25 [12:00<04:49, 36.24s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_18. No valid extraction found.\n\nLOG: Processing Image 'train_1_2.jpg'\n  Image Size (for Inference): (800, 522) | Prompt Chars: 1342\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  72%|███████▏  | 18/25 [12:24<03:48, 32.66s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_19. No valid extraction found.\n\nLOG: Processing Image 'train_1_9.jpg'\n  Image Size (for Inference): (495, 341) | Prompt Chars: 1329\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  76%|███████▌  | 19/25 [12:47<02:58, 29.74s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_20. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1493\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  80%|████████  | 20/25 [13:17<02:29, 29.94s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_21. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1740\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  84%|████████▍ | 21/25 [14:03<02:19, 34.85s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_22. No valid extraction found.\n\nLOG: Processing Image 'train_1_11.jpg'\n  Image Size (for Inference): (480, 300) | Prompt Chars: 1817\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  88%|████████▊ | 22/25 [14:43<01:48, 36.22s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_23. No valid extraction found.\n\nLOG: Processing Image 'train_1_2.jpg'\n  Image Size (for Inference): (800, 522) | Prompt Chars: 1773\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  92%|█████████▏| 23/25 [15:12<01:08, 34.12s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_24. No valid extraction found.\n\nLOG: Processing Image 'train_1_9.jpg'\n  Image Size (for Inference): (495, 341) | Prompt Chars: 1692\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions:  96%|█████████▌| 24/25 [15:50<00:35, 35.22s/it]","output_type":"stream"},{"name":"stdout","text":"  -> NOTE: Using fallback for question train_25. No valid extraction found.\n\nLOG: Processing Image 'train_1_20.jpg'\n  Image Size (for Inference): (500, 334) | Prompt Chars: 1436\n","output_type":"stream"},{"name":"stderr","text":"Processing Questions: 100%|██████████| 25/25 [16:23<00:00, 39.35s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\n📊 INFERENCE SUMMARY\nTotal Questions Processed: 25, Correct Guesses: 15\nAccuracy: 60.00%\nImages per Second: 0.03 img/s\nResults for this batch saved to: train_inference_results.csv\n\n🎉 Inference completed! Check train_inference_results.csv for detailed results.\n🧹 Cleaning up VRAM...\nVRAM cleaned up\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ===================================================================\n# Block 5: Post-Inference Analysis (NEW)\n# ===================================================================\nimport pandas as pd\n\ntry:\n    # Load the results from the training run\n    output_csv = \"train_inference_results.csv\"\n    df = pd.read_csv(output_csv)\n\n    print(f\"\\n--- Analysis of {output_csv} ---\")\n\n    # Display a count of the model's answers vs correct answers\n    print(\"\\nModel answer distribution:\")\n    print(df['model_answer'].value_counts())\n    print(\"\\nCorrect answer distribution:\")\n    print(df['correct_answer'].value_counts())\n\n    # The 'is_correct' column is already calculated during inference.\n    # We can directly calculate the accuracy from it.\n    if 'is_correct' in df.columns and not df['is_correct'].isnull().all():\n        # Ensure boolean type for correct calculation, handling potential non-boolean values\n        df['is_correct'] = df['is_correct'].astype(bool)\n        accuracy = df['is_correct'].mean() * 100\n        print(f\"\\n✅ Final Accuracy on the processed training set slice: {accuracy:.2f}%\")\n        \n        # Display rows where the model was incorrect\n        print(\"\\n🔍 Examples of incorrect answers:\")\n        incorrect_df = df[df['is_correct'] == False]\n        print(incorrect_df[['question_id', 'correct_answer', 'model_answer', 'reasoning']].head())\n\n    else:\n        print(\"\\n'is_correct' column not found or is empty. Cannot calculate accuracy.\")\n\nexcept FileNotFoundError:\n    print(f\"\\nCould not find the results file: {output_csv}. Please run the main inference block first.\")","metadata":{"_uuid":"705436a1-e806-4050-8a0c-b512b2b2d8f5","_cell_guid":"426040b3-607b-447d-b94e-2a61128dd3a2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-08-31T15:11:39.918306Z","iopub.execute_input":"2025-08-31T15:11:39.918524Z","iopub.status.idle":"2025-08-31T15:11:39.980179Z","shell.execute_reply.started":"2025-08-31T15:11:39.918506Z","shell.execute_reply":"2025-08-31T15:11:39.979558Z"}},"outputs":[{"name":"stdout","text":"\n--- Analysis of train_inference_results.csv ---\n\nModel answer distribution:\nmodel_answer\nA        11\nFalse     5\nB         4\nC         3\nD         1\nTrue      1\nName: count, dtype: int64\n\nCorrect answer distribution:\ncorrect_answer\nA        9\nB        6\nĐúng    4\nC        3\nSai      2\nD        1\nName: count, dtype: int64\n\n✅ Final Accuracy on the processed training set slice: 60.00%\n\n🔍 Examples of incorrect answers:\n  question_id correct_answer model_answer  \\\n0     train_1              B            A   \n4     train_5              B            A   \n7     train_8          Đúng        False   \n8     train_9          Đúng        False   \n9    train_10            Sai        False   \n\n                                           reasoning  \n0  Step 1: Phân tích câu hỏi\\n- Câu hỏi yêu cầu t...  \n4  Step 1: Phân tích câu hỏi: Câu hỏi yêu cầu phâ...  \n7  Step 1: Phân tích câu hỏi\\n- Câu hỏi yêu cầu x...  \n8  Step 1: Phân tích câu hỏi\\n- Câu hỏi yêu cầu x...  \n9  Step 1: Phân tích câu hỏi\\n- Câu hỏi yêu cầu x...  \n","output_type":"stream"}],"execution_count":8}]}